{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e13800c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82472ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dean/code/miniconda3/envs/dedup/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import faiss\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "import av\n",
    "import math\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from scipy.spatial.distance import cdist\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#VIDEO_DIR = \"/Volumes/Sudan/sudan_stuff\"\n",
    "VIDEO_DIR = \"input_videos\"\n",
    "EMB_FILE  = \"embeddings.npy\"\n",
    "ID_FILE   = \"embedding_ids.npy\"\n",
    "INDEX_PATH = \"clip_index.faiss\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23397c79",
   "metadata": {},
   "source": [
    "### Load GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be64160a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() : \n",
    "    device = \"cuda:1\"\n",
    "    print(f\"device:{device}\")\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"device:{device}\")\n",
    "else:\n",
    "    print(f\"Plain ol' CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541d8749",
   "metadata": {},
   "source": [
    "### Infer, index, store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58c946a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total segments in directory: 605\n",
      "Start process_video_directory\n",
      "    - embedding batch 1: adding 256 clips (total after this: 256)\n",
      "Indexed batch #1, total vectors indexed: 256\n",
      "    - embedding batch 2: adding 256 clips (total after this: 512)\n",
      "Indexed batch #2, total vectors indexed: 512\n",
      "    ‑- embedding batch 3 (final)\n",
      "✅ done: 604 clips added\n",
      "    final index.ntotal = 604\n",
      "Successfully processed 604 video clips\n",
      "Data written to positions 0-603 in memory arrays\n",
      "FAISS index saved to disk.\n"
     ]
    }
   ],
   "source": [
    "# Model config \n",
    "CKPT      = \"microsoft/xclip-base-patch32\"\n",
    "processor = AutoProcessor.from_pretrained(CKPT)\n",
    "model     = AutoModel.from_pretrained(CKPT).to(device)\n",
    "dim = 512\n",
    "BATCH = 256\n",
    "clip_time = 30 # In seconds\n",
    "\n",
    "# Create memmaps\n",
    "max_rows = scan_dir(VIDEO_DIR, clip_time)\n",
    "print(f\"number of total segments in directory: {max_rows}\")\n",
    "\n",
    "emb_memmap = create_memap(file_path=EMB_FILE, \n",
    "                          dtype=np.float32,\n",
    "                          shape=(max_rows, dim),\n",
    "                          init_value=0.0)\n",
    "\n",
    "# Create index \n",
    "index = faiss.IndexFlatL2(dim)\n",
    "\n",
    "name_dict, total_clips, final_write_ptr = process_video_directory(\n",
    "    VIDEO_DIR, processor,\n",
    "    model, index, emb_memmap,\n",
    "    BATCH, clip_time)\n",
    "\n",
    "with open(\"clip_name_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(name_dict, f)\n",
    "\n",
    "print(f\"Successfully processed {total_clips} video clips\")\n",
    "print(f\"Data written to positions 0-{final_write_ptr-1} in memory arrays\")\n",
    "\n",
    "faiss.write_index(index, INDEX_PATH)\n",
    "print(\"FAISS index saved to disk.\")\n",
    "\n",
    "assert final_write_ptr == total_clips, \"Mismatch between clips and write position!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5878b3dc",
   "metadata": {},
   "source": [
    "**Sanity check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30f28c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names: 604, embeds: 605\n",
      "⚠️ Dropping orphan embedding index(es): [604]\n",
      "✅ name_list and embeddings both have 604 entries\n",
      "ID    0 → file: 'TNS_0001_V.mp4', clip index: 0\n",
      "ID  302 → file: 'TNS_0030_V.mp4', clip index: 25\n",
      "ID  603 → file: 'TNS_0089_V.mp4', clip index: 2\n",
      "Index.ntotal = 604, embeddings loaded = 604\n"
     ]
    }
   ],
   "source": [
    "with open(\"clip_name_list.pkl\", \"rb\") as f:\n",
    "    name_dict = pickle.load(f)\n",
    "\n",
    "emb = np.load(EMB_FILE)   # shape = (N, D)\n",
    "\n",
    "print(f\"names: {len(name_dict)}, embeds: {emb.shape[0]}\")\n",
    "if emb.shape[0] > len(name_dict):\n",
    "    # drop any trailing embeddings with no name\n",
    "    extra = list(range(len(name_dict), emb.shape[0]))\n",
    "    print(f\"⚠️ Dropping orphan embedding index(es): {extra}\")\n",
    "    emb = emb[:len(name_dict)]\n",
    "elif emb.shape[0] < len(name_dict):\n",
    "    raise ValueError(f\"ⓧ Too few embeddings: {emb.shape[0]} vs {len(name_dict)} names\")\n",
    "\n",
    "# Basic length check\n",
    "assert len(name_dict) == emb.shape[0], (\n",
    "    f\"❌ Length mismatch: {len(name_dict)} names vs {emb.shape[0]} embeddings\"\n",
    ")\n",
    "print(f\"✅ name_list and embeddings both have {len(name_dict)} entries\")\n",
    "\n",
    "# Print a few sample mappings\n",
    "for idx in [0, len(name_dict)//2, len(name_dict)-1]:\n",
    "    fn, clip_idx = name_dict[idx]\n",
    "    print(f\"ID {idx:4d} → file: {fn!r}, clip index: {clip_idx}\")\n",
    "\n",
    "\n",
    "# Load FAISS index & confirm it matches our embeddings\n",
    "index = faiss.read_index(INDEX_PATH)\n",
    "print(f\"Index.ntotal = {index.ntotal}, embeddings loaded = {emb.shape[0]}\")\n",
    "assert index.ntotal == emb.shape[0], (\n",
    "    f\"❌ Index contains {index.ntotal} vectors but we have {emb.shape[0]} embeddings\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e56e9e",
   "metadata": {},
   "source": [
    "### Find duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45753aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded name_list (604 entries)\n",
      "Searching for pairs in a radius of: 0.01\n",
      "Total unique file pairs with duplicate clips: 2\n",
      "TNS_0024_V.mp4 (len: 594.6s) <-> TNS_0025_V.mp4 (len: 594.6s): 20 duplicate clips\n",
      "TNS_0030_V.mp4 (len: 2052.6s) <-> TNS_0031_V.mp4 (len: 2052.6s): 69 duplicate clips\n"
     ]
    }
   ],
   "source": [
    "with open(\"clip_name_list.pkl\", \"rb\") as f:\n",
    "    name_dict = pickle.load(f)\n",
    "print(f\"Loaded name_list ({len(name_dict)} entries)\")\n",
    "\n",
    "# Load FAISS index & embeddings\n",
    "index      = faiss.read_index(INDEX_PATH)\n",
    "emb_matrix = np.load(EMB_FILE)[:len(name_dict)]      # float32, shape=(N, D)\n",
    "\n",
    "# Radius search\n",
    "radius = 0.01\n",
    "print(f\"Searching for pairs in a radius of: {radius}\")\n",
    "lim, distance_matrix, identity_matrix = index.range_search(emb_matrix, radius)\n",
    "\n",
    "# Find duplicate pairs (IDs are positions in the index)\n",
    "query_ids = np.arange(emb_matrix.shape[0])               # one ID per embedding\n",
    "pairs     = find_duplicates(\n",
    "    lim,\n",
    "    distance_matrix,\n",
    "    identity_matrix,\n",
    "    query_ids\n",
    ")\n",
    "\n",
    "# Gather video durations\n",
    "video_lengths = {}\n",
    "for fn in os.listdir(VIDEO_DIR):\n",
    "    if not fn.lower().endswith((\".mp4\", \".mov\", \".avi\")):\n",
    "        continue\n",
    "    file_path = os.path.join(VIDEO_DIR, fn)\n",
    "    try:\n",
    "        container = av.open(file_path)\n",
    "        dur = container.duration or 0\n",
    "        video_lengths[fn] = dur / 1e6\n",
    "        container.close()\n",
    "    except Exception:\n",
    "        video_lengths[fn] = 0\n",
    "\n",
    "import cv2\n",
    "# Compute Laplacian variance (sharpness) for each video\n",
    "video_variance = {}\n",
    "for fn in os.listdir(VIDEO_DIR):\n",
    "    if not fn.lower().endswith((\".mp4\", \".mov\", \".avi\")):\n",
    "        continue\n",
    "    file_path = os.path.join(VIDEO_DIR, fn)\n",
    "    try:\n",
    "        container = av.open(file_path)\n",
    "        vs = container.streams.video[0]\n",
    "        # grab the first video frame\n",
    "        frame = next(container.decode(v=vs))\n",
    "        img = frame.to_ndarray(format=\"bgr24\")\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # compute Laplacian variance\n",
    "        lap = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "        video_variance[fn] = float(lap.var())\n",
    "        container.close()\n",
    "    except Exception:\n",
    "        video_variance[fn] = None\n",
    "\n",
    "# Count duplicates per file‐pair\n",
    "file_pair_counts = defaultdict(int)\n",
    "for a, b, distance in pairs:\n",
    "    fn_a, idx_a = name_dict[a]\n",
    "    fn_b, idx_b = name_dict[b]\n",
    "    if fn_a == fn_b:\n",
    "        continue\n",
    "    pair = tuple(sorted([fn_a, fn_b]))\n",
    "    file_pair_counts[pair] += 1\n",
    "\n",
    "# Print summary\n",
    "print(\"Total unique file pairs with duplicate clips:\", len(file_pair_counts))\n",
    "for (file1, file2), dup_count in file_pair_counts.items():\n",
    "    len1 = video_lengths.get(file1, 0)\n",
    "    len2 = video_lengths.get(file2, 0)\n",
    "    qual1 = video_variance.get(file1, 0)\n",
    "    qual2 = video_variance.get(file1, 0)\n",
    "    print(f\"{file1} (len: {len1:.1f}s) <-> {file2} (len: {len2:.1f}s): {dup_count} duplicate clips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb239d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "Done. Run:\n",
      "  tensorboard --logdir=runs/embeds\n",
      "Then open http://localhost:6006/#projector\n"
     ]
    }
   ],
   "source": [
    "# Reload your positional name_list\n",
    "with open(\"clip_name_list.pkl\", \"rb\") as f:\n",
    "    name_dict = pickle.load(f)\n",
    "\n",
    "emb_matrix = np.load(EMB_FILE)[:len(name_dict)]\n",
    "\n",
    "# Build metadata from name_list\n",
    "metadata = [ f\"{fn}[{idx}]\" for fn, idx in name_dict ]\n",
    "\n",
    "# Sanity check lengths match\n",
    "assert emb_matrix.shape[0] == len(metadata), (\n",
    "    f\"❌ {emb_matrix.shape[0]} embeddings vs {len(metadata)} metadata entries\"\n",
    ")\n",
    "\n",
    "# 5) Write to TensorBoard\n",
    "writer = SummaryWriter(log_dir=\"runs/embeds\")\n",
    "writer.add_embedding(\n",
    "    emb_matrix,\n",
    "    metadata=metadata,\n",
    "    tag=\"my_embeddings\"\n",
    ")\n",
    "writer.close()\n",
    "\n",
    "print(\"Done. Run:\\n  tensorboard --logdir=runs/embeds\\nThen open http://localhost:6006/#projector\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dedup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
