{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e13800c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82472ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dean/code/miniconda3/envs/dedup/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import faiss\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "import av\n",
    "import math\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from scipy.spatial.distance import cdist\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "VIDEO_DIR = \"/Volumes/Sudan/sudan_stuff\"\n",
    "#VIDEO_DIR = \"input_videos\"\n",
    "EMB_FILE  = \"embeddings.npy\"\n",
    "ID_FILE   = \"embedding_ids.npy\"\n",
    "INDEX_PATH = \"clip_index.faiss\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23397c79",
   "metadata": {},
   "source": [
    "### Load GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be64160a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() : \n",
    "    device = \"cuda:1\"\n",
    "    print(f\"device:{device}\")\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"device:{device}\")\n",
    "else:\n",
    "    print(f\"Plain ol' CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541d8749",
   "metadata": {},
   "source": [
    "### Infer, index, store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c946a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total segments in directory: 46555\n",
      "[Batch 1] Inference on 256 IDs: 0 … 255 → writing at rows 0 … 255\n",
      "[Batch 1] added to FAISS (index size now: 256)\n",
      "[Batch 2] Inference on 256 IDs: 256 … 511 → writing at rows 256 … 511\n",
      "[Batch 2] added to FAISS (index size now: 512)\n",
      "[Batch 3] Inference on 256 IDs: 512 … 767 → writing at rows 512 … 767\n",
      "[Batch 3] added to FAISS (index size now: 768)\n",
      "[Batch 4] Inference on 256 IDs: 768 … 1023 → writing at rows 768 … 1023\n",
      "[Batch 4] added to FAISS (index size now: 1024)\n",
      "[Batch 5] Inference on 256 IDs: 1024 … 1279 → writing at rows 1024 … 1279\n",
      "[Batch 5] added to FAISS (index size now: 1280)\n",
      "[Batch 6] Inference on 256 IDs: 1280 … 1535 → writing at rows 1280 … 1535\n"
     ]
    }
   ],
   "source": [
    "# Model config \n",
    "CKPT      = \"microsoft/xclip-base-patch32\"\n",
    "processor = AutoProcessor.from_pretrained(CKPT)\n",
    "model     = AutoModel.from_pretrained(CKPT).to(device)\n",
    "dim = 512\n",
    "BATCH = 256\n",
    "clip_time = 10 # In seconds\n",
    "\n",
    "# Create memmaps\n",
    "max_rows = scan_dir(VIDEO_DIR, clip_time)\n",
    "print(f\"number of total segments in directory: {max_rows}\")\n",
    "emb_memmap = create_memap(file_path=EMB_FILE, \n",
    "                          dtype=np.float32,\n",
    "                          shape=(max_rows, dim),\n",
    "                          init_value=0.0)\n",
    "\n",
    "id_memmap = create_memap(file_path=ID_FILE,\n",
    "                        dtype=np.int64,\n",
    "                        shape=(max_rows,),\n",
    "                        init_value=-1)\n",
    "\n",
    "# Create index \n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index = faiss.IndexIDMap2(index)\n",
    "\n",
    "name_dict, total_clips, final_write_ptr = process_video_directory(\n",
    "    VIDEO_DIR, processor,\n",
    "    model, index, emb_memmap,\n",
    "    id_memmap, BATCH, clip_time\n",
    ")\n",
    "\n",
    "print(f\"Successfully processed {total_clips} video clips\")\n",
    "print(f\"Data written to positions 0-{final_write_ptr-1} in memory arrays\")\n",
    "assert final_write_ptr == total_clips, \"Mismatch between clips and write position!\"\n",
    "\n",
    "faiss.write_index(index, INDEX_PATH)\n",
    "print(\"FAISS index saved to disk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e56e9e",
   "metadata": {},
   "source": [
    "### Find duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45753aef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faiss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load FAISS index & embedddings \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mfaiss\u001b[49m\u001b[38;5;241m.\u001b[39mread_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip_index.faiss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m emb_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)      \u001b[38;5;66;03m# float32, shape=(N, D)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m id_array   \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_ids.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)    \u001b[38;5;66;03m# int64 or int32, shape=(N,)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'faiss' is not defined"
     ]
    }
   ],
   "source": [
    "# Load FAISS index & embedddings \n",
    "index = faiss.read_index(\"clip_index.faiss\")\n",
    "emb_matrix = np.load(\"embeddings.npy\")      # float32, shape=(N, D)\n",
    "id_array   = np.load(\"embedding_ids.npy\")    # int64 or int32, shape=(N,)\n",
    "\n",
    "valid      = id_array >= 0\n",
    "emb_matrix = emb_matrix[valid]\n",
    "id_array   = id_array[valid]\n",
    "\n",
    "# Brute force query for entire embedding matrix\n",
    "radius = 0.001 \n",
    "print(f\"radius: {radius}\")\n",
    "lim, distance_matrix, identity_matrix = index.range_search(emb_matrix, radius)\n",
    "\n",
    "# Find duplicates\n",
    "pairs = find_duplicates(lim, distance_matrix, identity_matrix, id_array)\n",
    "\n",
    "# Reconstruct filenames \n",
    "with open(\"clip_name_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(name_dict, f)\n",
    "print(f\"Saved clip‐ID lookup to clip_name_dict.pkl ({len(name_dict)} entries)\")\n",
    "\n",
    "# Find length of each video\n",
    "video_lengths = {}\n",
    "for fn in os.listdir(VIDEO_DIR):\n",
    "    if not fn.lower().endswith((\".mp4\", \".mov\", \".avi\")):\n",
    "        continue\n",
    "    file_path = os.path.join(VIDEO_DIR, fn)\n",
    "    try:\n",
    "        container = av.open(file_path)\n",
    "        duration = container.duration\n",
    "        if duration is not None:\n",
    "            video_lengths[fn] = duration / 1e6  # seconds\n",
    "        else:\n",
    "            video_lengths[fn] = 0\n",
    "        container.close()\n",
    "    except Exception:\n",
    "        video_lengths[fn] = 0\n",
    "\n",
    "# Dictionary to count duplicate clips between file pairs\n",
    "file_pair_counts = defaultdict(int)\n",
    "\n",
    "for a, b, distance in pairs:\n",
    "    file_a, idx_a = name_dict.get(a, (\"unknown\", -1)) # unknown is fallback\n",
    "    file_b, idx_b = name_dict.get(b, (\"unknown\", -1))\n",
    "    if file_a == file_b:\n",
    "        continue  # Skip self-matches\n",
    "    #print(f\"{file_a} [clip {idx_a}] <-> {file_b} [clip {idx_b}] (distance: {distance:.4f})\")\n",
    "    \n",
    "    # Sort file names to avoid (A,B) and (B,A) being counted separately\n",
    "    file_pair = tuple(sorted([file_a, file_b]))\n",
    "    file_pair_counts[file_pair] += 1\n",
    "    \n",
    "print(\"Total unique file pairs with duplicate clips:\", len(file_pair_counts))\n",
    "# Print out duplicate file pairs and the number of duplicate clips\n",
    "for (file1, file2), dup_count in file_pair_counts.items():\n",
    "    len1 = video_lengths.get(file1, \"unknown\")\n",
    "    len2 = video_lengths.get(file2, \"unknown\")\n",
    "    print(f\"{file1} (len: {len1:.1f}s) <-> {file2} (len: {len2:.1f}s): {dup_count} duplicate clips\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb239d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "embeddings = np.load(\"embeddings.npy\")      # shape = (max_rows, dim)\n",
    "ids        = np.load(\"embedding_ids.npy\")    # shape = (max_rows,)\n",
    "\n",
    "# Filter out unused slots (id_memmap was init to -1)\n",
    "valid_mask = ids >= 0\n",
    "embeddings = embeddings[valid_mask]\n",
    "ids        = ids[valid_mask]\n",
    "\n",
    "# Create a TensorBoard writer\n",
    "log_dir = \"runs/embeds\"\n",
    "writer  = SummaryWriter(log_dir)\n",
    "\n",
    "# build human-readable labels ───\n",
    "id_to_label = {\n",
    "    cid: f\"{fn}[{idx}]\"\n",
    "    for cid, (fn, idx) in name_dict.items()\n",
    "}\n",
    "\n",
    "# metadata: only one entry per valid embedding\n",
    "metadata = [ id_to_label.get(i, \"unknown\") for i in ids ]\n",
    "\n",
    "# Sanity check\n",
    "assert embeddings.shape[0] == len(metadata), (\n",
    "    f\"Embeddings rows {embeddings.shape[0]} != metadata lines {len(metadata)}\"\n",
    ")\n",
    "\n",
    "writer.add_embedding(\n",
    "    embeddings,\n",
    "    metadata=metadata,\n",
    "    tag=\"my_embeddings\")\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print(f\"Done. Run:\\n  tensorboard --logdir={log_dir}\\nThen open http://localhost:6006/#projector\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dedup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
